{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('../data/microchip_tests.txt',\n",
    "                   header=None, names = ('test1','test2','released'))\n",
    "# info about dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset on 118 microchips (objects), there are results for two tests of quality control (two numerical variables) and information whether the microchip went into production. Variables are already centered, meaning that the column values have had their own mean values subtracted. Thus, the \"average\" microchip corresponds to a zero value in the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect at the first and last 5 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data manipulation with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:10, 'released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[0, 3], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put training data and class labels into separate numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:2].values\n",
    "y = data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an intermediate step, we can plot the data. Orange points correspond to defective chips, blue to normal ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='orange', label='Faulty')\n",
    "plt.xlabel(\"Test 1\")\n",
    "plt.ylabel(\"Test 2\")\n",
    "plt.title('2 tests of microchips. Logit with C=1')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to display the separating curve of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, grid_step=.01, poly_featurizer=None):\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_step),\n",
    "                         np.arange(y_min, y_max, grid_step))\n",
    "\n",
    "\n",
    "    # to every point from [x_min, m_max]x[y_min, y_max]\n",
    "    # we put in correspondence its own color\n",
    "    if poly_featurizer == None:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = clf.predict(poly_featurizer.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train logistic regression with regularization parameter $C = 1$- without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `sklearn`'s implementation of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit, X, y, grid_step=.01)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='orange', label='Faulty')\n",
    "plt.xlabel(\"Test 1\")\n",
    "plt.ylabel(\"Test 2\")\n",
    "plt.title('2 tests of microchips. Logit with C=%s' % C)\n",
    "plt.legend();\n",
    "\n",
    "print(\"Accuracy on training set:\", \n",
    "      round(logit.score(X_train, y_train), 3))\n",
    "\n",
    "print(\"Accuracy on testing set:\", \n",
    "      round(logit.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate and plot ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(clf, X_test):\n",
    "    probas_ = logit.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2)\n",
    "    plt.title('ROC AUC = %0.2f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(logit, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our classifier is not very good since the bounday is nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we create an object that will add polynomial features up to degree 7 to matrix $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following polynomial features of degree $d$ for two variables $x_1$ and $x_2$:\n",
    "\n",
    "$$\\large \\{x_1^d, x_1^{d-1}x_2, \\ldots x_2^d\\} =  \\{x_1^ix_2^j\\}_{i+j=d, i,j \\in \\mathbb{N}}$$\n",
    "\n",
    "For example, for $d=3$, this will be the following features:\n",
    "\n",
    "$$\\large 1, x_1, x_2,  x_1^2, x_1x_2, x_2^2, x_1^3, x_1^2x_2, x_1x_2^2, x_2^3$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=7)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1e-2\n",
    "logit = LogisticRegression(C=C, random_state=17)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit, X, y, grid_step=.01, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='orange', label='Faulty')\n",
    "plt.xlabel(\"Test 1\")\n",
    "plt.ylabel(\"Test 2\")\n",
    "plt.title('2 tests of microchips. Logit with C=%s' % C)\n",
    "plt.legend();\n",
    "\n",
    "print(\"Accuracy on training set:\", \n",
    "      round(logit.score(X_train, y_train), 3))\n",
    "\n",
    "print(\"Accuracy on testing set:\", \n",
    "      round(logit.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(logit, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now try increasing $C$ to 1. In doing this, we weaken regularization, and the solution can now have greater values (in absolute value) of model weights than previously. Now the accuracy of the classifier on the training set improves to 0.831."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "logit = LogisticRegression(C=C, random_state=17)\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "plot_boundary(logit, X, y, grid_step=.005, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='orange', label='Faulty')\n",
    "plt.xlabel(\"Test 1\")\n",
    "plt.ylabel(\"Test 2\")\n",
    "plt.title('2 tests of microchips. Logit with C=%s' % C)\n",
    "plt.legend();\n",
    "\n",
    "print(\"Accuracy on training set:\", \n",
    "      round(logit.score(X_train, y_train), 3))\n",
    "\n",
    "print(\"Accuracy on testing set:\", \n",
    "      round(logit.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(logit, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, why don't we increase $C$ even more - up to 10,000? Now, regularization is clearly not strong enough, and we see overfitting. Note that, with $C$=1 and a \"smooth\" boundary, the share of correct answers on the training set is not much lower than here. But one can easily imagine how our second model will work much better on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1e4\n",
    "logit = LogisticRegression(C=C, random_state=17)\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "plot_boundary(logit, X, y, grid_step=.005, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Released')\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='orange', label='Faulty')\n",
    "plt.xlabel(\"Test 1\")\n",
    "plt.ylabel(\"Test 2\")\n",
    "plt.title('2 tests of microchips. Logit with C=%s' % C)\n",
    "plt.legend();\n",
    "\n",
    "print(\"Accuracy on training set:\", \n",
    "      round(logit.score(X_train, y_train), 3))\n",
    "\n",
    "print(\"Accuracy on testing set:\", \n",
    "      round(logit.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(logit, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discuss the results, let's rewrite the function that is optimized in logistic regression with the form:\n",
    "\n",
    "$$\\large J(X,y,w) = \\mathcal{L} + \\frac{1}{C}||w||^2,$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\mathcal{L}$ is the logistic loss function summed over the entire dataset\n",
    "- $C$ is the reverse regularization coefficient (the very same $C$ from `sklearn`'s implementation of `LogisticRegression`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subtotals**:\n",
    "- the larger the parameter $C$, the more complex the relationships in the data that the model can recover (intuitively $C$ corresponds to the \"complexity\" of the model - model capacity)\n",
    "- if regularization is too strong i.e. the values of $C$ are small, the solution to the problem of minimizing the logistic loss function may be the one where many of the weights are too small or zeroed. The model is also not sufficiently \"penalized\" for errors (i.e. in the function $J$, the sum of the squares of the weights \"outweighs\", and the error $\\mathcal{L}$ can be relatively large). In this case, the model will underfit as we saw in our first case.\n",
    "- on the contrary, if regularization is too weak i.e. the values of $C$ are large, a vector $w$ with high absolute value components can become the solution to the optimization problem. In this case, $\\mathcal{L}$ has a greater contribution to the optimized functional $J$. Loosely speaking, the model is too \"afraid\" to be mistaken on the objects from the training set and will therefore overfit as we saw in the third case.\n",
    "- logistic regression will not \"understand\" (or \"learn\") what value of $C$ to choose as it does with the weights $w$. That is to say, it can not be determined by solving the optimization problem in logistic regression. We have seen a similar situation before -- a decision tree can not \"learn\" what depth limit to choose during the training process. Therefore, $C$ is the a model hyperparameter that is tuned on cross-validation; so is the max_depth in a tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complicated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with dataset where given various features of the flight we are asked to predict wheather there will be a delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/flight_delays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of categorical features it is a good idea to onehotencode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode our labels to be 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = coder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit `sklearn` implementation of `SGDClassifier` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn-linear-model-sgdclassifier). You also have to split dataset appropriately to the train and test sets and plot ROC curve and AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cross-validation to choose appropriate constant for regularization coefficient $C$ for $L2$ regularizer (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
